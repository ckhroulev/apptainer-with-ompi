#+TITLE: Apptainer (Singularity) containers with MPI

* Apptainer (Singularity) containers with Open MPI and InfiniBand

These notes document my attempt to build an [[https://apptainer.org/][Apptainer]] (or
[[https://sylabs.io/singularity/][SingularityCE]]) base container that can be used to run MPI-based
software in "hybrid" mode.

Proper MPI support requires attention to two issues:

1. compatibility between MPI libraries in the container and on a host
2. supporting network hardware

Apptainer supports both widely used open source MPI implementations
([[https://www.open-mpi.org/][Open MPI]] and [[https://www.mpich.org/][MPICH]]), but these notes focus on Open MPI.

The image is built in 2 steps:

1. The base image =base.sif= containing support libraries for the
   network hardware and utilities needed to test if it works.
2. The final image =openmpi.sif= includes everything in =base.sif=,
   the Open MPI installation in =/opt/ompi=, and the "MPI Hello World"
   program =/opt/mpi_hello= used to test Open MPI.

   All the commands needed to build Open MPI are in a Bash script
   =scripts/openmpi.sh=. This script can be used to build the matching
   Open MPI version on the host.

Run =make= to build both images.

This separation makes it easier to separate issues related to version
compatibility from ones related to hardware support.

The definition files =base.def= and =openmpi.def= should be minimal.
There are no unnecessary software packages, no environment variables.
They document a minimal working setup.

My hope is that this write up may save you some time; at least it
should make it easier to ask the right questions when talking to HPC
support staff.

Edits (however minor), corrections, improvements, etc are always
welcome.

* Software compatibility

** Open MPI

The standard advice is "use the version installed on the host", but
this is not always practical: we may want to support multiple hosts or
the host may not have Open MPI installed.

Moreover, we need to try to do what we can to simplify reproducible
research and that may require using more current Open MPI versions
than a certain host provides.

The plot below shows which Open MPI version combinations appear to be
compatible. (See [[file:version_compatibility/README.md][=version_compatibility=]] for the
setup used to produce it.)

#+attr_html: :width 800px
#+CAPTION: Compatibility between container and host Open MPI versions
#+NAME:   fig:ompi-version-compatibility
[[file:version_compatibility/grid.png]]

Based on this I would recommend using Open MPI version 4.0.0 or newer
in the container because these versions are compatible with Open MPI
3.0.3 and newer on the host. Your mileage may vary.

Note, also, that [[https://www.open-mpi.org/software/ompi/major-changes.php][Open MPI 4.1.x is ABI compatible with 4.0.x and 4.0.x
is ABI compatible with 3.1.x and 3.0.x]].

*** Compatibility between Open MPI and its dependencies

It is worth pointing out that Open MPI relies on external libraries
for some of its features and we need to use versions of these that are
compatible with the chosen Open MPI version.

In particular, we might have to build some libraries from source
instead of using a package system if our container is based on a
distribution that is significantly older than the chosen Open MPI
version.

** Compatibility between the host kernel and the container OS

If you run a container and it fails with the error message saying
=FATAL: kernel too old=, it is likely that the /host/ kernel is not
supported by =glibc= in the container.

The relevant threshold is this: /glibc 2.26 and newer require Linux
3.2 or newer./

For example, given a host that runs CentOS 6.10, [[https://distrowatch.com/table.php?distribution=centos][this DistroWatch.com
page]] shows that it uses Linux 2.6.32.

To build a container that would run on this host we need to pick a
Linux distribution version that

- uses =glibc= older than 2.26,
- is not past its end-of-life,
- includes software versions (such as compilers) that are recent enough
  for our purposes.

In this particular case CentOS 7 should work: it uses =glibc= 2.17 and
is supported until June of 2024.

* InfiniBand and RDMA support 

Supporting InfiniBand in a container is not that different from the
same task on a host. Your HPC staff should be able to tell you which
libraries are needed.

See [[https://www.mellanox.com/products/infiniband-drivers/linux/mlnx_ofed][Mellanox OpenFabrics Enterprise Distribution for Linux]] for binary
packages provided by NVIDIA and [[https://www.mellanox.com/support/mlnx-ofed-matrix?mtag=linux_sw_drivers][=MLNX_OFED=: Firmware - Driver
Compatibility Matrix]] to see which driver version is needed for a
particular model of the interconnect.

RHEL 7 documentation lists these [[https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-infiniband_and_rdma_related_software_packages][InfiniBand and RDMA related software
packages]].

#+include: base.def example :lines "17-41"

#+BEGIN_QUOTE
Some packages are needed to configure IB hardware, to update firmware,
etc. (This is one of the differences from IB support on a host.)
#+END_QUOTE

Note: recommended packages =libibverbs-utils= and =infiniband-diags=
are used to test InfiniBand support below.

** Checking if IB devices are available

Running =ibv_devices= from =libibverbs-utils= should produce output
similar to this:
   
#+BEGIN_EXAMPLE
  % singularity exec base.sif ibv_devices
      device                 node GUID
      ------              ----------------
      mlx4_0              7cfe900300c40490
#+END_EXAMPLE

Running the same command on a laptop that does not have IB devices
gives this:

#+BEGIN_EXAMPLE
  % singularity exec base.sif ibv_devices
  Failed to get IB devices list: Unknown error -38
#+END_EXAMPLE

Alternatively, run =ibstat= from =infiniband-diags=:

#+BEGIN_EXAMPLE
  % singularity exec base.sif ibstat
  CA 'mlx4_0'
          CA type: MT4099
          Number of ports: 1
          Firmware version: 2.42.5000
          Hardware version: 1
          Node GUID: 0x7cfe900300c40490
          System image GUID: 0x7cfe900300c40493
          Port 1:
                  State: Active
                  Physical state: LinkUp
                  Rate: 40
                  Base lid: 49
                  LMC: 0
                  SM lid: 1
                  Capability mask: 0x02514868
                  Port GUID: 0x7cfe900300c40491
                  Link layer: InfiniBand
#+END_EXAMPLE

Without IB devices:
#+BEGIN_EXAMPLE
  % singularity exec base.sif ibstat
  ibpanic: [2137592] main: stat of IB device 'mthca0' failed: No such file or directory
#+END_EXAMPLE

** Checking inter-node communication using IB

Here we use =ibv_rc_pingpong= from =libibverbs-utils=:

Start an interactive job. On a system using [[https://slurm.schedmd.com/][Slurm]] this would require
something like
#+BEGIN_SRC bash
srun -p debug --nodes=1 --exclusive -I --pty /bin/bash
#+END_SRC

Then, run this on a compute node to start =ibv_rc_pingpong= in its
/server/ mode:
#+BEGIN_EXAMPLE
% hostname && singularity exec openmpi.sif ibv_rc_pingpong
n2
  local address:  LID 0x0091, QPN 0x03006b, PSN 0x5a83c9, GID ::
  remote address: LID 0x0031, QPN 0x002962, PSN 0x850520, GID ::
8192000 bytes in 0.01 seconds = 9496.59 Mbit/sec
1000 iters in 0.01 seconds = 6.90 usec/iter
#+END_EXAMPLE

Next, use the =hostname= output from above (here: =n2=) to run
=ibv_rc_pingpong= on the login node:
#+BEGIN_EXAMPLE
% singularity exec openmpi.sif ibv_rc_pingpong n2
  local address:  LID 0x0031, QPN 0x002962, PSN 0x850520, GID ::
  remote address: LID 0x0091, QPN 0x03006b, PSN 0x5a83c9, GID ::
8192000 bytes in 0.01 seconds = 9630.57 Mbit/sec
1000 iters in 0.01 seconds = 6.80 usec/iter
#+END_EXAMPLE

* Building Open MPI

To be able to re-use a container we need to build Open MPI with
support for all types of network hardware we intend to support.

Installing support libraries in standard should be enough to get Open
MPI to use them: it will [[https://www-lb.open-mpi.org/faq/?category=building#default-build][try to find support for all hardware and
environments by looking for support libraries and header files in
standard locations; skip them if not found]].

The standard sequence
#+BEGIN_SRC bash
configure --prefix=${prefix} && make && make install
#+END_SRC
is likely to be sufficient, however one could use flags such as
=--with-verbs= to force =configure= to stop if a required dependency
was not found. See [[https://www-lb.open-mpi.org/faq/?category=building#build-p2p][How do I build Open MPI with support for {my
favorite network type}?]] for more details.

Run
#+BEGIN_SRC bash
ompi_info --parsable | grep :openib
#+END_SRC
/after/ the build is complete to check if =openib= support was included.
  
** Configuring Open MPI

Open MPI uses a [[https://www.open-mpi.org/faq/?category=tuning#mca-def][Modular Component Architecture (MCA)]], i.e. a set of
framework components and modules. Much of its behavior can be adjusted
using MCA parameters that can be set using command-line options /or/
configuration files.

A comment in such a file says the following
#+BEGIN_QUOTE
Note that this file is only applicable where it is visible (in a
filesystem sense). Specifically, MPI processes each read this file
during their startup to determine what default values for MCA
parameters should be used. mpirun does not bundle up the values in
this file from the node where it was run and send them to all nodes;
the default value decisions are effectively distributed. Hence, these
values are only applicable on nodes that "see" this file. If $sysconf
is a directory on a local disk, it is likely that changes to this file
will need to be propagated to other nodes. If $sysconf is a directory
that is shared via a networked filesystem, changes to this file will
be visible to all nodes that share this $sysconf.
#+END_QUOTE

This means that configuration files on the host will not be seen by
Open MPI in a container.

/We may need to modify a container to use settings appropriate on a
given host./

*** Finding Open MPI's configuration files

Here's a way to find the system-wide configuration file:
#+BEGIN_EXAMPLE
  % ompi_info --all --parsable | grep mca_base_param_files:value
  mca:mca:base:param:mca_base_param_files:value:/home/username/.openmpi/mca-params.conf,/opt/scyld/openmpi/4.0.5/intel/etc/openmpi-mca-params.conf
#+END_EXAMPLE

Here =/opt/scyld/openmpi/4.0.5/intel/etc/openmpi-mca-params.conf= is a
system-wide configuration file that we may need to examine to find
settings for this host.

The following command will print system-wide MCA settings (assuming
your module system sets =MPI_HOME=):
#+BEGIN_SRC bash
  cat ${MPI_HOME}/etc/openmpi-mca-params.conf | grep -Ev "^#|^$"
#+END_SRC

*** Useful MCA parameters

Open MPI 4.x without UCX:
#+BEGIN_EXAMPLE
# disable the TCP byte transport layer
btl = vader,self,openib
# Use openib without UCX in Open MPI 4.0 and later:
btl_openib_allow_ib = 1
#+END_EXAMPLE

Increasing verbosity for testing:
#+BEGIN_SRC bash
    mpirun --mca btl_base_verbose 100 --mca mca_base_verbose stdout \
           ...
#+END_SRC

** Testing an Open MPI installation

It is useful to include a simple "MPI Hello World" program in the base
image. It looks like most compatibility and hardware support issues
crop up during initialization (in the =MPI_Init()= call), so a test
program as simple as that seems to do the job.

The two recommended test steps are
1. try using =mpirun= /in the container/
2. try using =mpirun= /on the host/.

*** Using =mpirun= in the container

#+BEGIN_EXAMPLE
% singularity exec openmpi.sif mpirun -n 4 /opt/mpi_hello
Hello from process 0/4!
Hello from process 1/4!
Hello from process 2/4!
Hello from process 3/4!
#+END_EXAMPLE

We can also increase verbosity to check if Open MPI succeeded at
initializing InfiniBand devices:
#+BEGIN_EXAMPLE
% singularity exec openmpi.sif mpirun --mca btl_base_verbose 100 --mca mca_base_verbose stdout -n 1 /opt/mpi_hello | grep openib
[hostname:pid] mca: base: components_register: found loaded component openib
[hostname:pid] mca: base: components_register: component openib register function successful
[hostname:pid] mca: base: components_open: found loaded component openib
[hostname:pid] mca: base: components_open: component openib open function successful
[hostname:pid] select: initializing btl component openib
[hostname:pid] openib BTL: rdmacm CPC unavailable for use on mlx4_0:1; skipped
[hostname:pid] [rank=0] openib: using port mlx4_0:1
[hostname:pid] select: init of component openib returned success
[hostname:pid] mca: base: close: component openib closed
[hostname:pid] mca: base: close: unloading component openib
#+END_EXAMPLE

with =hostname= and =pid= replaced with the host name and =pid= with
the process ID.

*** Using =mpirun= on the host

A successful run looks like this:
#+BEGIN_EXAMPLE
% mpirun -n 4 singularity exec openmpi.sif /opt/mpi_hello
Hello from process 0/4!
Hello from process 1/4!
Hello from process 2/4!
Hello from process 3/4!
#+END_EXAMPLE

When MPI initialization fails you may see
- =Hello from process 0/1!= repeated 4 times,
- an error message from Open MPI,
- no output (process hangs).

To check IB initialization:
#+BEGIN_SRC bash
  mpirun -n 1 \
         --mca btl_base_verbose 100 \
         --mca mca_base_verbose stdout \
         singularity exec openmpi.sif /opt/mpi_hello | grep openib
#+END_SRC

This command should produce the same output as the one above (=mpirun=
in the container).

* To do

- Supporting hosts that use Slurm (install =munge= and PMIx 3.2.2 or
  newer).
- Document building containers using MPICH instead of Open MPI
  (probably [[https://mvapich.cse.ohio-state.edu/][MVAPICH]]).
- Update to use [[https://openucx.readthedocs.io/en/master/running.html#openmpi-with-ucx][UCX]] (and =libfabric=?). See [[https://openucx.readthedocs.io/en/master/running.html#running-mpi][Running UCX]] for more info.

  Add =--mca pml_base_verbose 100= to verbosity options (to check if
  UCX *is* actually used).

  Build Open MPI =--without-verbs= to [[https://www.open-mpi.org/faq/?category=openfabrics#ofa-device-error][avoid an error message about
  device initialization]].

#+BEGIN_EXAMPLE
  --------------------------------------------------------------------------
  WARNING: There was an error initializing an OpenFabrics device.

    Local host:   chinook01
    Local device: mlx4_0
  --------------------------------------------------------------------------
#+END_EXAMPLE
  
- Make sure that the list of packages in =base.def= does not include
  anything unnecessary.

* Acknowledgments

This work was inspired by [[https://blogs.ed.ac.uk/mhagdorn/2020/08/14/using-singularity-to-containerise-a-scientific-model/][a blog post by Magnus Hagdorn]].

I'd like to thank [[https://www.gi.alaska.edu/services/research-computing-systems][Research Computing Systems staff at UAF]] and [[https://nas.nasa.gov/][NASA
Advanced Supercomputing (NAS) Division support staff]] for their help.

The specific output of "MPI Hello World" used here is inspired by
Singularity docs and the [[https://youtu.be/jl2cT9gkxwo][recording of the 2022-1-6 Singularity CE
community meeting]]. Details regarding building Open MPI in a way that
supports Slurm come from the same recording.

Some of the ideas come from the discussion of the
[[https://github.com/apptainer/singularity/issues/876][Apptainer/singularity issue 876]].
